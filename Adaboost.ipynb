{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adaboost.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Uploading data from my Drive"
      ],
      "metadata": {
        "id": "xkYQ3SF2879v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! gdown https://drive.google.com/drive/folders/1eJPlwS6bd_3SUlm-rh_t7KglTaR4zrIQ?usp=sharing\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "ZYRjSknp88bH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8aae24-6dc9-4e8c-e0e4-f2fad769be17"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "JMMrSVMU8wXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import exp, sqrt, log\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "from itertools import combinations\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "sStIQ9yx8whb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data model from CNN model and normilze the array"
      ],
      "metadata": {
        "id": "0Aov4zwCp_T4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.load(\"/content/gdrive/MyDrive/saved_data/x_train.npy\", allow_pickle=True)\n",
        "x_test = np.load(\"/content/gdrive/MyDrive/saved_data/x_test.npy\", allow_pickle=True)\n",
        "y_train = np.load(\"/content/gdrive/MyDrive/saved_data/y_train.npy\", allow_pickle=True)\n",
        "y_test = np.load(\"/content/gdrive/MyDrive/saved_data/y_test.npy\", allow_pickle=True)\n",
        "\n",
        "x_train = x_train/255.\n",
        "x_test = x_test/255.\n",
        "\n",
        "y_train_demo, y_test_demo = [], []\n",
        "for i in y_train:\n",
        "    if i[0] == 1:\n",
        "        y_train_demo.append(1)\n",
        "    else:\n",
        "        y_train_demo.append(-1)\n",
        "for i in y_test:\n",
        "    if i[0] == 1:\n",
        "        y_test_demo.append(1)\n",
        "    else:\n",
        "        y_test_demo.append(-1)\n",
        "        \n",
        "y_train = np.array(y_train_demo)\n",
        "y_test = np.array(y_test_demo)\n",
        "\n",
        "x_train_demo, x_test_demo = [], []\n",
        "for i in x_train:\n",
        "    x_train_demo.append(i.flatten())\n",
        "for i in x_test:\n",
        "    x_test_demo.append(i.flatten())\n",
        "\n",
        "\n",
        "x_train = np.array(x_train_demo)\n",
        "x_test = np.array(x_test_demo)"
      ],
      "metadata": {
        "id": "UkQX7Q-Qp_eQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building AdaBoost algorithm"
      ],
      "metadata": {
        "id": "GI6lKduCl6sW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaBoost:\n",
        "    \"\"\"this class represents the AdaBoost algorithm for classify the data representations\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.DecTree = None\n",
        "        self.DecTree_weights = None\n",
        "        self.errors = None\n",
        "        self.weights = None\n",
        "        self.epochs = None\n",
        "\n",
        "    def _check_data(self, X, y):\n",
        "        assert set(y) == {-1, 1}, 'data must be Â±1'\n",
        "        return X, y\n",
        "\n",
        "    def _initialize_weights(self, X, y):\n",
        "        \"\"\"Initialize weights to (1 / size of the train set)\"\"\"\n",
        "        self.weights = np.zeros(shape=(self.epochs, X.shape[0]))\n",
        "        self.DecTree = np.zeros(shape=self.epochs, dtype=object)\n",
        "        self.DecTree_weights = np.zeros(shape=self.epochs)\n",
        "        self.errors = np.zeros(shape=self.epochs)\n",
        "        \n",
        "        self.weights[0] = np.ones(shape=X.shape[0]) / X.shape[0]\n",
        "        \n",
        "        \n",
        "    def update_weights(self, epoch, alpha, y, pred):\n",
        "        \"\"\"\n",
        "        this function compute the weight for the point that if finds error in it or not\n",
        "        and computes the new weight by that\n",
        "        \"\"\"\n",
        "        self.weights[epoch] = (self.weights[epoch - 1] * np.exp(-alpha * y * pred))\n",
        "    \n",
        "    def normalize_weights(self, epoch):\n",
        "        \"\"\"this function normalize the weight by the sum\"\"\"\n",
        "        self.weights[epoch] /= self.weights[epoch].sum()\n",
        "                \n",
        "    def fit(self, X: np.ndarray, y: np.ndarray, epochs: int):\n",
        "        \"\"\" Fit the model using training data and this function is the main algorithm \n",
        "        for the AdaBoost that initialize the weight and \n",
        "        computes the alpha for the min error\"\"\"\n",
        "        \n",
        "        X, y = self._check_data(X, y)\n",
        "        self.epochs = epochs\n",
        "\n",
        "        self._initialize_weights(X, y)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            cur_weights = self.weights[epoch]\n",
        "            stump = DecisionTreeClassifier(max_depth=1, max_leaf_nodes=2)\n",
        "            stump = stump.fit(X, y, sample_weight=cur_weights)\n",
        "\n",
        "            stump_pred = stump.predict(X)\n",
        "            err = cur_weights[(stump_pred != y)].sum()\n",
        "            alpha = 0.5 * np.log((1 - err) / err)\n",
        "\n",
        "                        \n",
        "            if epoch+1 < epochs:\n",
        "                self.update_weights(epoch + 1,alpha, y, stump_pred)\n",
        "                self.normalize_weights(epoch + 1)\n",
        "\n",
        "            self.DecTree[epoch] = stump\n",
        "            self.DecTree_weights[epoch] = alpha\n",
        "            self.errors[epoch] = err\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\" The predictions of the model after fitting the model \"\"\"\n",
        "        pred = np.array([decision.predict(X) for decision in self.DecTree])\n",
        "        return np.sign(np.dot(self.DecTree_weights, pred))\n",
        "    "
      ],
      "metadata": {
        "id": "AH_mDTCel62U"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running AdaBoost algorithm and checking model accuracy"
      ],
      "metadata": {
        "id": "ltEdM9GYeJe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adaboost = AdaBoost()\n",
        "model = adaboost.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "train_acc = model.predict(x_train)\n",
        "print(\"Train Accuracy: {:.2f}%\".format(metrics.accuracy_score(y_train, train_acc) * 100))\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "train_err = (model.predict(x_train) != y_train).mean()\n",
        "print(f'Train error: {train_err:.1%}')\n",
        "print(\"Accuracy: {:.2f}%\".format(metrics.accuracy_score(y_test, y_pred) * 100))"
      ],
      "metadata": {
        "id": "h1DTd6dy7PPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaee164f-6480-491a-fcb8-2d04bba9fd3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 90.90%\n",
            "Train error: 9.1%\n",
            "Accuracy: 72.24%\n"
          ]
        }
      ]
    }
  ]
}