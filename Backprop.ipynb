{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Backprop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Uploading data from my Drive"
      ],
      "metadata": {
        "id": "xkYQ3SF2879v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! gdown https://drive.google.com/drive/folders/1eJPlwS6bd_3SUlm-rh_t7KglTaR4zrIQ?usp=sharing\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "ZYRjSknp88bH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd9b0ee-42c8-4cc5-d125-53d71775e04e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "JMMrSVMU8wXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "ujfLcOvmjjIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d398fd-f287-4188-a0df-661f02b1bfc9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading data model from CNN model and normilze the array(balck and white) "
      ],
      "metadata": {
        "id": "ek1XeYHNjjP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.load(\"/content/gdrive/MyDrive/saved_data/x_train.npy\", allow_pickle=True)\n",
        "x_test = np.load(\"/content/gdrive/MyDrive/saved_data/x_test.npy\", allow_pickle=True)\n",
        "y_train = np.load(\"/content/gdrive/MyDrive/saved_data/y_train.npy\", allow_pickle=True)\n",
        "y_test = np.load(\"/content/gdrive/MyDrive/saved_data/y_test.npy\", allow_pickle=True)\n",
        "\n",
        "x_train = x_train/255.\n",
        "x_test = x_test/255."
      ],
      "metadata": {
        "id": "oeCGwoAjjjWS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "adding algorithm parameters"
      ],
      "metadata": {
        "id": "pMaJ7_bhjje3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "learning_rate = 0.0005\n",
        "training_epochs = 80\n",
        "batch_size = 256\n",
        "display_step = 1"
      ],
      "metadata": {
        "id": "amN6oleLjjlJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j-WO6vxHjjrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def next_batch(num_split, feature, labels):\n",
        "    ind = np.arange(0, len(feature))\n",
        "    np.random.shuffle(ind)\n",
        "    ind = ind[:num_split]\n",
        "    feature_shuffle = [feature[i].flatten() for i in ind]\n",
        "    labels_shuffle = [labels[i] for i in ind]\n",
        "\n",
        "    return np.asarray(feature_shuffle), np.asarray(labels_shuffle)\n"
      ],
      "metadata": {
        "id": "aYU01mb4jjxp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the Neural Network and runnig the algorithm"
      ],
      "metadata": {
        "id": "vD4d1uYJjj4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, [None, 22500])\n",
        "y = tf.placeholder(tf.float32, [None, 2])\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([22500, 256], stddev=0.03), name='W1')\n",
        "b1 = tf.Variable(tf.random_normal([256]), name='b1')\n",
        "z1 = tf.nn.relu(tf.matmul(x,W1)+b1)\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([256, 128], stddev=0.03), name='W2')\n",
        "b2 = tf.Variable(tf.random_normal([128]), name='b2')\n",
        "z2 = tf.nn.relu(tf.matmul(z1,W2)+b2)\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([128, 64], stddev=0.03), name='W3')\n",
        "b3 = tf.Variable(tf.random_normal([64]), name='b3')\n",
        "z3 = tf.nn.relu(tf.matmul(z2,W3)+b3)\n",
        "\n",
        "W4 = tf.Variable(tf.random_normal([64, 2], stddev=0.03), name='W4')\n",
        "b4 = tf.Variable(tf.random_normal([2]), name='b4')\n",
        "\n",
        "\n",
        "log = tf.matmul(z3, W4) + b4\n",
        "pred = tf.nn.softmax(tf.matmul(z3, W4) + b4)\n",
        "\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=log))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch in range(training_epochs):\n",
        "        avg_cost = 0.\n",
        "        total_batch = int(len(x_train)/batch_size)\n",
        "        for i in range(total_batch):\n",
        "            batch_xs, batch_ys = next_batch(batch_size, x_train, y_train)\n",
        "            _, c, acc = sess.run([optimizer, cost, accuracy], feed_dict={x: batch_xs, y: batch_ys})\n",
        "            avg_cost += c / total_batch\n",
        "        if (epoch+1) % display_step == 0:\n",
        "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost), \"acc=\", \"{:.5}\".format(acc))\n",
        "    print(\"Optimization Finished!\")\n",
        "    \n",
        "    x_test_flat = []\n",
        "    for i in x_test:\n",
        "        x_test_flat.append(i.flatten())\n",
        "    x_test_flat = np.array(x_test_flat)\n",
        "    \n",
        "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    print(\"Accuracy:\", accuracy.eval({x: x_test_flat, y: y_test}))"
      ],
      "metadata": {
        "id": "sStIQ9yx8whb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ef4714-a65d-4b70-d765-41e68a029f4f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Epoch: 0001 cost= 0.799107522 acc= 0.52344\n",
            "Epoch: 0002 cost= 0.677708346 acc= 0.67188\n",
            "Epoch: 0003 cost= 0.605731291 acc= 0.83203\n",
            "Epoch: 0004 cost= 0.453389627 acc= 0.86719\n",
            "Epoch: 0005 cost= 0.295134902 acc= 0.89844\n",
            "Epoch: 0006 cost= 0.225273612 acc= 0.91406\n",
            "Epoch: 0007 cost= 0.203871648 acc= 0.93359\n",
            "Epoch: 0008 cost= 0.182173088 acc= 0.92969\n",
            "Epoch: 0009 cost= 0.149692709 acc= 0.94141\n",
            "Epoch: 0010 cost= 0.163126971 acc= 0.90625\n",
            "Epoch: 0011 cost= 0.131931464 acc= 0.94922\n",
            "Epoch: 0012 cost= 0.119927533 acc= 0.97266\n",
            "Epoch: 0013 cost= 0.107575840 acc= 0.96094\n",
            "Epoch: 0014 cost= 0.101135464 acc= 0.97656\n",
            "Epoch: 0015 cost= 0.118921620 acc= 0.94922\n",
            "Epoch: 0016 cost= 0.110746482 acc= 0.96875\n",
            "Epoch: 0017 cost= 0.143160866 acc= 0.89844\n",
            "Epoch: 0018 cost= 0.121881900 acc= 0.97266\n",
            "Epoch: 0019 cost= 0.091724247 acc= 0.98438\n",
            "Epoch: 0020 cost= 0.133669189 acc= 0.94141\n",
            "Epoch: 0021 cost= 0.113204451 acc= 0.94922\n",
            "Epoch: 0022 cost= 0.089624494 acc= 0.96875\n",
            "Epoch: 0023 cost= 0.093563605 acc= 0.96094\n",
            "Epoch: 0024 cost= 0.085164375 acc= 0.98047\n",
            "Epoch: 0025 cost= 0.084742788 acc= 0.95703\n",
            "Epoch: 0026 cost= 0.087982218 acc= 0.94922\n",
            "Epoch: 0027 cost= 0.106242098 acc= 0.96875\n",
            "Epoch: 0028 cost= 0.067914208 acc= 0.97266\n",
            "Epoch: 0029 cost= 0.086092640 acc= 0.97266\n",
            "Epoch: 0030 cost= 0.090439266 acc= 0.96484\n",
            "Epoch: 0031 cost= 0.071666579 acc= 0.97656\n",
            "Epoch: 0032 cost= 0.084895854 acc= 0.96094\n",
            "Epoch: 0033 cost= 0.085539283 acc= 0.96094\n",
            "Epoch: 0034 cost= 0.079427316 acc= 0.97656\n",
            "Epoch: 0035 cost= 0.070718456 acc= 0.97656\n",
            "Epoch: 0036 cost= 0.070420490 acc= 0.98438\n",
            "Epoch: 0037 cost= 0.076300089 acc= 0.97656\n",
            "Epoch: 0038 cost= 0.063119876 acc= 0.98438\n",
            "Epoch: 0039 cost= 0.082428887 acc= 0.95703\n",
            "Epoch: 0040 cost= 0.077717242 acc= 0.95312\n",
            "Epoch: 0041 cost= 0.079289899 acc= 0.96875\n",
            "Epoch: 0042 cost= 0.071902065 acc= 0.97266\n",
            "Epoch: 0043 cost= 0.066680178 acc= 0.98047\n",
            "Epoch: 0044 cost= 0.082185892 acc= 0.94531\n",
            "Epoch: 0045 cost= 0.085761716 acc= 0.96094\n",
            "Epoch: 0046 cost= 0.065716494 acc= 0.97656\n",
            "Epoch: 0047 cost= 0.064210369 acc= 0.98828\n",
            "Epoch: 0048 cost= 0.069753852 acc= 0.96094\n",
            "Epoch: 0049 cost= 0.072171854 acc= 0.98438\n",
            "Epoch: 0050 cost= 0.057277540 acc= 0.98828\n",
            "Epoch: 0051 cost= 0.058670765 acc= 0.96875\n",
            "Epoch: 0052 cost= 0.047787685 acc= 0.98828\n",
            "Epoch: 0053 cost= 0.068617900 acc= 0.97266\n",
            "Epoch: 0054 cost= 0.064861580 acc= 0.98828\n",
            "Epoch: 0055 cost= 0.053578832 acc= 0.98047\n",
            "Epoch: 0056 cost= 0.059893563 acc= 0.99219\n",
            "Epoch: 0057 cost= 0.088867128 acc= 0.98438\n",
            "Epoch: 0058 cost= 0.116176804 acc= 0.99609\n",
            "Epoch: 0059 cost= 0.117122668 acc= 0.95312\n",
            "Epoch: 0060 cost= 0.056631599 acc= 0.98047\n",
            "Epoch: 0061 cost= 0.066436910 acc= 0.96484\n",
            "Epoch: 0062 cost= 0.056298044 acc= 0.98438\n",
            "Epoch: 0063 cost= 0.045802435 acc= 0.98047\n",
            "Epoch: 0064 cost= 0.052937463 acc= 0.96484\n",
            "Epoch: 0065 cost= 0.039069628 acc= 0.99219\n",
            "Epoch: 0066 cost= 0.037215274 acc= 0.98438\n",
            "Epoch: 0067 cost= 0.045839912 acc= 1.0\n",
            "Epoch: 0068 cost= 0.055438675 acc= 0.99219\n",
            "Epoch: 0069 cost= 0.041102026 acc= 0.99219\n",
            "Epoch: 0070 cost= 0.038603768 acc= 0.99609\n",
            "Epoch: 0071 cost= 0.030694948 acc= 0.99609\n",
            "Epoch: 0072 cost= 0.033877928 acc= 0.98828\n",
            "Epoch: 0073 cost= 0.029762067 acc= 1.0\n",
            "Epoch: 0074 cost= 0.030866005 acc= 0.99219\n",
            "Epoch: 0075 cost= 0.030557575 acc= 0.98828\n",
            "Epoch: 0076 cost= 0.024104402 acc= 1.0\n",
            "Epoch: 0077 cost= 0.048994485 acc= 0.99219\n",
            "Epoch: 0078 cost= 0.035670574 acc= 0.98047\n",
            "Epoch: 0079 cost= 0.039868902 acc= 0.97656\n",
            "Epoch: 0080 cost= 0.041129498 acc= 0.98047\n",
            "Optimization Finished!\n",
            "Accuracy: 0.8059937\n"
          ]
        }
      ]
    }
  ]
}